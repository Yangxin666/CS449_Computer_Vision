{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.rochester.edu/assets/images/ur-logo.svg\">\n",
    "\n",
    "# <center>[CSC 249/449: Machine Vision](https://www.cs.rochester.edu/~cxu22/t/249F20/)</center>\n",
    "\n",
    "## Homework Submission\n",
    "After completed the homework notebook. \n",
    "- Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`, as well as your NetID below.\n",
    "- `Kernel`$\\rightarrow$ `Restart & Run All` (in the menubar).\n",
    "- You can generated zip file using following command:\n",
    "    ```python\n",
    "    NetID=''\n",
    "    make_submission(NetID)\n",
    "    ```\n",
    "- Double-check **generated zip file**, text, math, code, outputs, figures. Re-run if needed.\n",
    "- Sumbit the zip file via blackboard.\n",
    "- 1% deduction of late assignment total score per hour passing the deadline.\n",
    "---------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Neural Network Continued\n",
    "### Problem 2.1\n",
    "\n",
    "In this problem, we will try to optimize a Convex function with Adam optimizer.  \n",
    "The function is similar to the Problem4 in the last assignment, except we want to find the $x$ so that\n",
    "$$\n",
    "x=\\underset{x\\in [-15,15]}{\\operatorname{argmin}} f(x)\n",
    "$$\n",
    "\n",
    "You will try to use optimizer defined below to find the desired $x$ (Hint: should be aroung 1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs249 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = lambda x: 0.08*x.pow(2)+torch.sin(x)\n",
    "x = torch.unsqueeze(torch.linspace(-15, 15, 1000), dim=1) \n",
    "y = f(x)\n",
    "plt.scatter(x,y,marker='^',color = \"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7bb8e34be6df3b898ae43b4f7ca67a1",
     "grade": true,
     "grade_id": "cell-cf56852a27cab0a4",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "4.999439\n",
      "4.043033\n",
      "3.2543273\n",
      "2.6845875\n",
      "2.2821481\n",
      "1.9813094\n",
      "1.729879\n",
      "1.4874113\n",
      "1.2202438\n",
      "0.89912826\n",
      "0.5014047\n",
      "0.017594397\n",
      "-0.54199654\n",
      "-1.1427879\n",
      "-1.7184088\n",
      "-2.1780982\n",
      "-2.456985\n",
      "-2.5454822\n",
      "-2.466588\n",
      "-2.2540665\n",
      "-1.9465417\n",
      "-1.5884278\n",
      "-1.2299304\n",
      "-0.9204235\n",
      "-0.6966402\n",
      "-0.5761188\n",
      "-0.56003976\n",
      "-0.63901806\n",
      "-0.7965578\n",
      "-1.0098538\n",
      "-1.2498763\n",
      "-1.4830668\n",
      "-1.6762016\n",
      "-1.8033227\n",
      "-1.8509893\n",
      "-1.8193941\n",
      "-1.7204161\n",
      "-1.5746495\n",
      "-1.4080614\n",
      "-1.2479426\n",
      "-1.1183165\n",
      "-1.0360779\n",
      "-1.009133\n",
      "-1.0365427\n",
      "-1.1097418\n",
      "-1.2141573\n",
      "-1.331235\n",
      "-1.4411697\n",
      "-1.5262489\n",
      "-1.574049\n",
      "-1.5794922\n",
      "-1.5452576\n",
      "-1.4806997\n",
      "-1.3997036\n",
      "-1.3179008\n",
      "-1.2497303\n",
      "-1.2059435\n",
      "-1.1920546\n",
      "-1.2079037\n",
      "-1.248176\n",
      "-1.3036501\n",
      "-1.3629937\n",
      "-1.4149013\n",
      "-1.4502265\n",
      "-1.4636459\n",
      "-1.4544652\n",
      "-1.4264293\n",
      "-1.3866498\n",
      "-1.3439379\n",
      "-1.3069242\n",
      "-1.2823707\n",
      "-1.2740052\n",
      "-1.2820559\n",
      "-1.3034909\n",
      "-1.3328508\n",
      "-1.3634951\n",
      "-1.3890233\n",
      "-1.404585\n",
      "-1.4077963\n",
      "-1.3990705\n",
      "-1.3813189\n",
      "-1.35913\n",
      "-1.3376476\n",
      "-1.3214179\n",
      "-1.3134644\n",
      "-1.314766\n",
      "-1.3242146\n",
      "-1.3390183\n",
      "-1.3554375\n",
      "-1.3696777\n",
      "-1.3787411\n",
      "-1.3810445\n",
      "-1.3766712\n",
      "-1.3672218\n",
      "-1.3553237\n",
      "-1.3439395\n",
      "-1.3356555\n",
      "-1.3321134\n",
      "-1.3337097\n"
     ]
    }
   ],
   "source": [
    "# Adam (Adaptive Momemt Estimation)\n",
    "x_init = torch.tensor(7.0, requires_grad=True)\n",
    "optimizer = torch.optim.Adam([x_init], lr=1)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    loss=f(x_init)\n",
    "    loss.backward() # calculate gradients\n",
    "    optimizer.step()\n",
    "    print(x_init.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfT0lEQVR4nO3df5Ac9Znf8fcjCc6CkIDNFkiCWIAJVfjKyHhLyVVsylgYI44gLzGHtLHhKiQ6Yqjy5VJJ4UpV7HL+cS65uHLGJ5eIKezKCYEBGflAmDUC/UAYa4UXLMwBsiyhlcbSAnv+ASPZWj35Y3rQaDTd0zPT07/m86ra2pn+9k5/W6N99jvP95e5OyIiUl6zsq6AiIj0lwK9iEjJKdCLiJScAr2ISMkp0IuIlNycrCvQytlnn+0LFy7MuhoiIoWxY8eON9x9qFVZLgP9woULGR8fz7oaIiKFYWZ7w8qUuhERKTkFehGRklOgFxEpOQV6EZGSU6AXESk5BXoRkTyoVmD9RVD9ZeIvrUAvIpIH41+A3+6GHV9I/KUV6EVEslYZg33frT1+/buJt+oV6EVEslStwFNXNxzwxFv1CvQiIlnactPJxxJu1SvQi4hkpTIGb2xpUZBsq16BXkQkK08vCy/b93Bil1GgFxHJwp614NXwcj+W2KUU6EVEsrDtsxGFBqMziV1KgV5EJG171gIRgXzu/EQvp0AvIpK2yNb8LBiZTPRyCvQiImmKbM0nm7Kpa7vDlJndA1wHHHL3PwyO3Q9cEpxyJvAP7r6oxc/uAX5D7a6OuvtwIrUWESmqqNb87NP6csk4Lfp7gWsaD7j7Te6+KAjuDwFR44CuDM7tf5Dv46JAIiI9e3UVkbn5U8/sy2XbBnp33wy81arMzAz4E+C+hOvVnZ/cWVsUaOKLWddERORk45+PKEw+N9/wyj35GHDQ3V8LKXfgCTPbYWYro17IzFaa2biZjU9NTXVek2oF9vy/2uNffEetehHJl1dXhZfZnL7k5ut6DfQriG7Nf9TdLweWAreb2RVhJ7r7ancfdvfhoaGhzmvykzuB+gSDY7UlP0VE8mL89vCyBCdHtdJ1oDezOcANwP1h57j7/uD7IWAdsLjb60VqbM3X7XtArXoRyYc9a6klOFrpz0ibRr206K8C/t7dWyaVzOx0Mzuj/hi4GtjZw/XCndCab6BWvYjkwbbPhZclPDmqlbaB3szuA54FLjGzSTO7NShaTlPaxszmm9ljwdNzgK1m9gLwY+BRd388uao3eP27rY/vCzkuIpKWyhhwNKTQ+tYB26jtOHp3XxFy/E9bHDsAXBs83g1c1mP94rGwv1deS9/MPTeVaoiInGTzDeFlfRo336wcM2Ojxp4qfSMiWZmegJnfhpf3adx8s3IE+pFJmDW3dZnSNyKSlaevCy+bfXoqaRsoS6CH9ukbEZE0VStQ3R9enlJrHsoU6JW+EZE8eS5ijmiKrXkoU6BX+kZE8uTAo+FlKbbmoUyBHpS+EZF8mJ4gdIJUyq15KFugV/pGRPIgqhM25dY8lC3Qj0yCvad1mdI3IpKW0E7YdCZINStXoAfwsBloSt+ISAr2rA0vS2mCVLPyBfpWa97URfWCi4gkIWpdmwzSNlDGQD86Ez765sD3062LiAyW6QmyXtemlfIFeogYfQNMv5hePURksGz+1+FlKaxSGaacgT7q49FTf5xaNURkgFQr8Pbu1mWzT8usNQ9lDfQjk4QuzHl4Up2yIpK8iTsjCi21arRSzkAPqFNWRFK1N3Szvcw6YevKG+jVKSsiaTp2pPXxjNM2EG+HqXvM7JCZ7Ww49mUz229mE8HXtSE/e42ZvWJmu8ws6nNN+tQpKyJJqYxFFGabtoF4Lfp7gWtaHP+auy8Kvh5rLjSz2cA3gKXApcAKM7u0l8p2LGr0jTplRSQpUbtIZZy2gRiB3t03A2918dqLgV3uvtvdfwesBZZ18Trdi/oHVqesiCShWonYRSq7sfONesnR32FmLwapnbNalC8A9jU8nwyOtWRmK81s3MzGp6ameqhWg5HJ2kpxYbbclMx1RGRwRQ3uyHDsfKNuA/0q4CJgEVAB/qrXirj7ancfdvfhoaGhXl/uuKhW/Rubk7uOiAymsHXnc9AJW9dVoHf3g+4+4+7HgLuppWma7QfOb3h+XnAsXe1a9a/dnV5dRKRcotadz0EnbF1Xgd7M5jU8HQF2tjhtO3CxmV1gZqcCy4H13VyvZ1Gt+u0aUy8iXdoU0e2Yg07YujjDK+8DngUuMbNJM7sV+Esz+6mZvQhcCfzH4Nz5ZvYYgLsfBe4AfgC8DDzg7i/16T6itfv4pFa9iHSqWoF3Xm9dZnNyk7aB0HUCjnP3FS0Ofyvk3APAtQ3PHwNOGnqZibkLwjcD2L4SLv736dZHRIotaskDj5iZn4Hyzoxtpla9iCTp9ZBd62afVpuZnyODE+ghulN2+0qNqxeR+GZCljzIocEK9O06R6Jmt4mI1FUrhC+cmJ/RNnWDFehHJom85Tef1Ro4ItLetpvDy3I02qZusAI9tM+dbfxkOvUQkeI6+MPWx3M0SarR4AV6qI3ACXPkEOx9ML26iEix5HylylYGM9C3+4v7zI1K4YhIa1si9oXNYdoGBjXQQ3SrHuCpViszi8hAq1bg6G9CCvOxUmUrgxvo270hhysaWy8iJ4qaJJWTlSpbGdxAD+1b9dtXKoUjIsdFTZLKaWseBj3QtxtuCbDhMgV7Eak59rusa9CVwQ70EG+qsoK9iFQr4GHxIp+jbeoU6KF9Cgfg8cu1RILIIBv/QnhZTkfb1CnQQ7wUjs/A+gsV7EUG1b6HWh/PeX4eFOiPi5PCmanC+osU7EUGTcHWtmmmQN9oNGxLsAYz70SvcyEi5VOwtW2axdlh6h4zO2RmOxuO/U8z+3sze9HM1pnZmSE/uyfYiWrCzMYTrHf/xMnXHxzTMgkig6Rga9s0i9OivxdoniY6Bvyhu38IeBX4YsTPX+nui9x9uLsqpmxkMl6wf+ZGeHi+0jgiZVfAtW2atQ307r4ZeKvp2BPBnrAAPwLO60PdshOncxZqs2fXf0DBXqTMCri2TbMkcvT/FtgQUubAE2a2w8xWJnCt9IzOEOufZ+Zt5exFyqqga9s06ynQm9l/BY4Cfxtyykfd/XJgKXC7mV0R8VorzWzczManpqZ6qVZy4gZ75exFyqmga9s06zrQm9mfAtcB/8bdWw5Xcff9wfdDwDpgcdjruftqdx929+GhoaFuq5W8uJv8PnMj/HJjf+siIukq6No2zboK9GZ2DfBfgOvd/Z2Qc043szPqj4GrgZ2tzs29OMMuATYuUbAXKZOCrm3TLM7wyvuAZ4FLzGzSzG4F7gLOAMaCoZPfDM6db2aPBT96DrDVzF4Afgw86u6P9+Uu0tBJsNe6OCLFV+C1bZrNaXeCu69ocfhbIeceAK4NHu8GLuupdnkz6rBmNuEz5AIbLoOlL8BZH0qlWiLSB89FjB8pyGibOs2M7VTcnL1WvBQptgOPtj5esPw8KNB3J24a5/GPaIy9SBFNT1AbHd5KsdI2oEDfvTjB3o/C1pv6XxcRSdamZeFlBUvbgAJ9b+IE+6nNGokjUiTVCrzzeusym1O4tA0o0Pcuzro4G69SCkekKKImSXmbgRg5pUDfq1iLoDlsXZ5KdUSkR3sfaH189mnxB2PkjAJ9EuIE+6lNWiZBpAiOHcm6BolToE9KnGD/zI1K4YjkWclG29Qp0CcpTifN5hv6Xw8R6c6mT4eXFXC0TZ0CfdLajcR581mNwhHJo2oF3tnbuqyAk6QaKdD3Q7sUztPXpVMPEYkvasmDAqdtQIG+P9rtUHWsCq/dnVp1RCSGsCUPoNBpG1Cg7592w7C2r1THrEheRHXCzj690GkbUKDvr3YpHHXMiuTD5uLvCxtFgb6f2qVw3nxWrXqRrFUr8Pbu1mUF74StU6Dvt3YpnM0j6dRDRFqLWvKg4J2wdQr0aYhK4bz5I61bL5KlvfeHl5UgbQMxA72Z3WNmh8xsZ8Ox95rZmJm9Fnw/K+RnbwnOec3Mbkmq4oXS7qPfU9ekUw8ROVnYkgclSdtA/Bb9vUBzNLoTeNLdLwaeDJ6fwMzeC3wJ+OfAYuBLYX8QSi+qVX+4ola9SBb2rI0oLEfaBmIGenffDLzVdHgZ8O3g8beBT7f40U8BY+7+lrtPA2Oc/AdjMLRrGTz9x+nUQ0SO2/a58LKSpG2gtxz9Oe5eCR7/EjinxTkLgH0NzyeDYycxs5VmNm5m41NTUz1UK8eiWvXVSbXqRdI0PQEcDSm00qRtIKHOWHd3wpd8i/saq9192N2Hh4aGkqhW/rTN1atVL5KaqKVI5s5Prx4p6CXQHzSzeQDB90MtztkPnN/w/Lzg2OCKzNVPaly9SBqqFaiGhKKCbhcYpZdAvx6oj6K5BXikxTk/AK42s7OCTtirg2ODa2SyNqU6zLab06uLyKCKWsCsoNsFRok7vPI+4FngEjObNLNbga8CnzSz14CrgueY2bCZ/V8Ad38L+O/A9uDrK8GxwRbVyXNwLLVqiAysA3/X+vjsuYXdLjDKnDgnufuKkKIlLc4dB/5dw/N7gHu6ql1ZjUzCmlMI7Qja+yC8/zOpVklkYFQiGlPHfp9ePVKkmbGZifh4+MxN6VVDZNBsuj68rIRpG1Cgz07kx8Nj2oVKpB/2rIVjh1uX2ZxSpm1AgT5bUSNwNNRSJHnbPhteVtLWPCjQZ2tkktBuEj+sCVQiSdqzFghpsZe4NQ8K9DkQ0YrYOJirRYj0xYC25kGBPnujM4S26o9UNIFKJAmvrmJQW/OgQJ8TEa0JTaAS6U21AuOfDy8veWseFOjzYXQGmN26TBOoRHqzJWq4spW+NQ8K9DkS8Z9NQy1FujM9AW9sCS+ffVpqVcmSAn1eRA21fPpfpVcPkTLZeHV0eYnWnI+iQJ8XUUMtj72joZYinXp1FRyJ2ttiVulWqQyjQJ8rEZ1CmkAlEt/0RHQH7IDk5usU6PNkdAZmzW1dprXqReKZnoANH44+p2Qbi7SjQJ83FvGWRK2hLSK1oZQbPtLmpHJtExiHAn3eRHUOHfh+atUQKZxqBb53IZEpUBi41jwo0OdPux2o1CkrcrLpCVg3v7ZGVKTB6YBt1HWgN7NLzGyi4evXZvbnTed83Mx+1XDOf+u5xoMgqlWvoZYiJ6qMtc/J1w1QB2yjWDtMteLurwCLAMxsNrVNv9e1OHWLu0dsty4nGZmENda6rPp6unURybPKGDzVZqw8UBtlU/6lDsIklbpZAvzc3fcm9HoSlb7RTFkZdNMTsGZWzCDPQOblGyUV6JcD94WU/ZGZvWBmG8zsg2EvYGYrzWzczManpqImOQwIpW9ETlatwMPzglSNx/yhwczLN+o50JvZqcD1wHdbFD8PvN/dLwO+Dnwv7HXcfbW7D7v78NDQUK/VKj7NlBU5rh7g182Hw53MJ5k1sHn5Rkm06JcCz7v7weYCd/+1u/82ePwYcIqZnZ3ANQdERE7x6YgNjkXKpDLWRYAHBfnjkgj0KwhJ25jZuWZmwePFwfXeTOCagyFqpmx1r2bKSrntWVsblBA3D99o7gIF+QZdj7oBMLPTgU8Cf9Zw7DYAd/8m8BngP5jZUaAKLHf3uIk1geiZsuNfgI/dn15dRNIQeyRNiLkLBj4n36ynQO/ubwPvazr2zYbHdwF39XKNgXfqmVB9u3XZvgcABXopiekJ2HA58TtZWxhVO7IVzYzNu5HJ8PQNKH0j5fDupKduA/UsBfkIPbXoJSVR6ZttN8OSJ9Kri0iSqpVaK77jjtY6dbjGoUBfBFHpG+0pK0VVrcD6i2Cm2t3PqwUfm1I3RdBuobO9D6ZXF5EkVCvwSJdBftQV5DukFn1RRLXqn1kO7z+aanVEuhZnY5BWFNy7phZ9UUQOF5vRTFkphm6CvFrwPVOgL5K5C8LLtKesFMFTnSxkq5E0SVGgL5Ko9W+0p6zk3aur4PD+eOeOukbTJEiBvnAi1r/RnrKSV5UxGP98vHPVik+cAn3RjM6Avad1mfaUlTyanoi5pIFSNf2iQF9EHjHCRpuSSN5sXBrjJE186icF+kKKWr5Ym5JIjuxZC0fa9B1ppcm+U6AvotEZtCmJ5N70BGxb0eYk7f6UBgX6wtKmJJJj1Uq88fJqyadCgb6otCmJ5Nm2m9ufo47X1CjQF1m7VS1FslAZg4M/jD5HQT5VCvRFduqZ4WVa1VKy0jZ1qLCTtp7/xc1sj5n91MwmzGy8RbmZ2V+b2S4ze9HMLu/1mhKImikL8NrdqVVFBKjNfvXDESeY8vIZSOpP65Xuvsjdh1uULQUuDr5WAqsSuqYAkZ2y21cqVy/pajf7de78dOohJ0jjM9Qy4Dte8yPgTDObl8J1B0PUUEuAre2Gt4kkZOdXo8u1aXdmkgj0DjxhZjvMrNViKwuAfQ3PJ4NjJzCzlWY2bmbjU1NTCVRrkES06qeeVqte+q9agRe/GHGCxstnKYlA/1F3v5xaiuZ2M7uimxdx99XuPuzuw0NDQwlUa4C0y3luvSmdesjg2jQSXa68fKZ6DvTuvj/4fghYByxuOmU/cH7D8/OCY5KkqLXqpzZrtqz0T7UCbz0XcYJG2WStp3fAzE43szPqj4GrgZ1Np60Hbg5G3/wL4FfuXunlutJCu4/FT12TTj1k8ES25jXKJg96/VN7DrDVzF4Afgw86u6Pm9ltZnZbcM5jwG5gF3A3EHNRaulYVKv+cEUrW0rypieiW/MaZZML5p6/GWrDw8M+Pn7SkHyJY80pQMgyxvYeWFFNtTpScg/Ni1id0mA0YqCAJMrMdoQMcVfyrHwifrH8MPzsf6VXFSm36YnoJYjVms8NBfqyaZcPnfjP6piVZDwVtaGIaThljijQl1FUrh5gw2UK9tKbyhgcVmu+KBToy2hkkrZvrYK99GLzsohCtebzRoG+rOIMaXv8cs2alc5VxmAmolNfrfncUaAvtTZvr8/Auvlq2Utnolrzs09Xaz6HFOjLLNZEFa+lcTTGXuJo15qP2iNBMqNAX3Zxd/LZuAQenq9UjkSLzM1r4bK8UqAfBO1G4dQdrsC6ebDG1MKXk0W15m2OljrIsYiFzKU0RiZh3XlQ7WAtuY1LOrvGe+bB0udh7rmd/ZwUR1Rr3hXk80yBflCMTMKa2UTOnO1F/dPACWbXgv9ZH+rPNSU9GmlTaErdDJLRGdJ9y2dqHb1KBRXfpogNvzXSJvcU6AfN6Ez8nH2SNi6Bh85VZ28RVcbgWMSG3xppk3sK9INoZDKbYH/kYC29o9Z9sWikTeEp0A+qkclg6GUG/wU0lLM4NNKmFBToB93oTC3gp93CP1yB51rtJS+5EjnSRmvNF0XXo27M7HzgO9R2mXJgtbv/n6ZzPg48AvwiOPSwu3+l22tKH3Xz8bvXUTwHvl/L2187oWGZebRnbXRrfsXv062PdK2X4ZVHgf/k7s8H+8buMLMxd/9Z03lb3P26Hq4jedXqY3unwf/IQVj/Abh+l4J93mz7bHiZxs0XStepG3evuPvzwePfAC8DGfTwSa7UU0Fxl14AmHkbtt3cvzpJ5/asBSKCucbNF0oiOXozWwh8GGi1S/AfmdkLZrbBzD4Y8RorzWzczManpqaSqJZkrZPO3oNjGo2TJ1GteY2bL5yeA72Z/SPgIeDP3f3XTcXPA+9398uArwPfC3sdd1/t7sPuPjw0NNRrtSQv6i38ODYu0ZLJefDqKiJb8xo3Xzg9BXozO4VakP9bd3+4udzdf+3uvw0ePwacYmZn93JNKai4wV6boWSrWoHxz0ecoHHzRdR1oDczA74FvOzu/zvknHOD8zCzxcH13uz2mlJwcYK9z8D6CxXss7LlpohC07j5guqlRf8vgc8BnzCzieDrWjO7zcxuC875DLDTzF4A/hpY7u4d9NJJ6cTJ289UNcY+C5UxeGNLePns09KriySq6+GV7r4VsDbn3AXc1e01pKRGZ2oLnUU58P1a5+y5n0inTgJPRyxcBsrNF5hmxko24qRxNl6lFE5aXl0FHrFwmXLzhaZAL9lpu+yCw9blqVRloLXtgFVuvugU6CU7cVbRnNqk8fX9tmkkulyTowpPgV6yNTJJ2/+GG5cohdMve9bCW63mOdYpZVMG2kpQshenc3brcvjk06lUpy+qFdhwORyO+IOV9r671QpsWxF9jlI2paAWveRDWVM40xO1P2Lr5kcHeTi+7+4ag70P9rde1QqsW9jmJIWHstA7KfkQJ19fpFE40xOwZhZs+HB3P//MjbWAv2ZO8stCVCvwyEXA7yJOUgdsmSjQS360zdcXZBROZSwI8EnMDQw2WE9qR67pidqni2Mh68zXqQO2VBToJV/atSLznMKpVuDhefDU1cm/9rtpnR5a+NMTMT9hqAO2bBToJYcKOAqnWoH1F7fPw/csaOF3GvDf/ZQRg1I2paNAL/kzOkPb/5p5SuFUK/DIhbUNVFJTD/gW/QmnMlY7J+6njLT3DpZUaHil5FO7IZf1FE7Wa+HEToc0mxXcY4/77kLtE04ilLIpKwV6ya+5C6C6P7x841UwciC7vWa7CfJzF5wYTBvTJO3mEvTVLKVsSkypG8mvOKNwNt+QVm1O1GmQn7ugtpBbVIv53b120/61VJAvOwV6ybd2AejNZ9MfhdNNkO8kJfLu9otp/HoqyA8CBXopgBijcNLaa7ajID+rfSs+Sr8D/twFCvIDotc9Y68xs1fMbJeZ3dmi/A/M7P6g/DkzW9jL9WRAxRmFk8Zes5225JMKovWAn+SImF7+AEnh9LJn7GzgG8BS4FJghZld2nTarcC0u38A+BrwP7q9ngy4dkGz33vNViuw4SMxT54VfzP0ToxMNuTxu9Trz0sh9TLqZjGwy913A5jZWmAZ8LOGc5YBXw4ePwjcZWamfWOlK+1G4cxUYdvNsOSJZK/bSUu+03x8txSspQO9pG4WAPsank8Gx1qe4+5HgV8B72v1Yma20szGzWx8amqqh2pJacUJoAfHkl35MY9BXqRDuemMdffV7j7s7sNDQ0NZV0fyKk5L9pkbkxmJ08myAZpsJDnWS6DfD5zf8Py84FjLc8xsDvBPgDd7uKZIvE7JjUt6C/aVsc6WDdDoFcmxXgL9duBiM7vAzE4FlgPrm85ZD9wSPP4MsFH5eelZnLXroRbsO13et76OfCdBXi15ybmuA32Qc78D+AHwMvCAu79kZl8xs+uD074FvM/MdgF/AZw0BFOkK3H2moXjy/vGad13vI680jVSDJbHBvbw8LCPj49nXQ0pgk7Xh/nEkycuhDY9UdvLteNNQjSjVPLFzHa4+3Crstx0xop0pdNhhhuXwDcMzjH4G+tuJyjl5KVgFOil+DoN9uuAqeB7p5STlwJSoJdyiBvsp4HN1Brxm4F/6OAaCvJSUAr0Uh5xRuKs43im5hjxW/VaG0YKTIFeyqO+FkzYf+t6a/5o8PwoMVr1fVq3RiRFCvRSPu8u79uksTVfF9WqH3V1ukopKNBLeTWv1Pg8x1vzdUeBHY0HZmmFRykd7Rkr5VcP2qPZVkMkK2rRi4iUnAK9iEjJKdCLiJScAr2ISMkp0IuIlFwuV680sylgb5c/fjbwRoLVyVJZ7qUs9wG6lzwqy31Ab/fyfndvuT1fLgN9L8xsPGypzqIpy72U5T5A95JHZbkP6N+9KHUjIlJyCvQiIiVXxkC/OusKJKgs91KW+wDdSx6V5T6gT/dSuhy9iIicqIwtehERaaBALyJScqUI9GZ2o5m9ZGbHzGy44fhCM6ua2UTw9c0s6xlH2L0EZV80s11m9oqZfSqrOnbDzL5sZvsb3otrs65TJ8zsmuDffZeZ3Zl1fXphZnvM7KfB+zCedX06YWb3mNkhM9vZcOy9ZjZmZq8F38/Kso5xhdxLX35PShHogZ3ADdT2C2r2c3dfFHzdlnK9utHyXszsUmA58EHgGuBvzGx2+tXrydca3ovHsq5MXMG/8zeApcClwIrg/SiyK4P3oWjjz++l9v+/0Z3Ak+5+MfBk8LwI7uXke4E+/J6UItC7+8vu/krW9UhCxL0sA9a6+xF3/wWwC1icbu0G1mJgl7vvdvffAWupvR+SMnffDLzVdHgZ8O3g8beBT6dZp26F3EtflCLQt3GBmf3EzDaZ2ceyrkwPFgD7Gp5PBseK5A4zezH4yFqIj9eBMvzbN3LgCTPbYWYrs65MAs5x90rw+JfAOVlWJgGJ/54UJtCb2Q/NbGeLr6iWVQX4p+7+YeAvgDVm9o/TqXG4Lu8l99rc1yrgImARtfflr7Ks64D7qLtfTi0VdbuZXZF1hZLitfHiRR4z3pffk8JsJejuV3XxM0eAI8HjHWb2c+CfAZl2QHVzL8B+4PyG5+cFx3Ij7n2Z2d3A3/W5OknK/b99J9x9f/D9kJmto5aaatW/VRQHzWyeu1fMbB5wKOsKdcvdD9YfJ/l7UpgWfTfMbKjeYWlmFwIXA7uzrVXX1gPLzewPzOwCavfy44zrFFvwC1g3Qq3TuSi2Axeb2QVmdiq1TvH1GdepK2Z2upmdUX8MXE2x3otW1gO3BI9vAR7JsC496dfvSWFa9FHMbAT4OjAEPGpmE+7+KeAK4Ctm9nvgGHCbu6fS+dGtsHtx95fM7AHgZ8BR4HZ3n8myrh36SzNbRO1j9R7gzzKtTQfc/aiZ3QH8AJgN3OPuL2VcrW6dA6wzM6j9/q9x98ezrVJ8ZnYf8HHgbDObBL4EfBV4wMxupba8+Z9kV8P4Qu7l4/34PdESCCIiJVfq1I2IiCjQi4iUngK9iEjJKdCLiJScAr2ISMkp0IuIlJwCvYhIyf1/6KBIdTxa6UkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y,marker='^',color = \"orange\")\n",
    "plt.scatter(x_init.detach().numpy(),f(x_init).detach().numpy(),marker='^',color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2\n",
    "\n",
    "In convolutional neural network, a convolutional layer is actually implemented in **cross correlation**. \n",
    "\n",
    "To keep the consistency with convolutional neural network, implemente forward functions of 2D **corss correlation** layer.     \n",
    "\n",
    "1. The operation should work for 3D image tensor of shape (C,H,W) where C denotes the number of channels.   \n",
    "2. The operation should support **stride and padding**.   \n",
    "3. [useful link](https://cs231n.github.io/convolutional-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "img=numpy.array([[[2,3,4],[5,3,1],[2,4,2],[4,3,1]],[[4,5,4],[1,3,1],[7,4,2],[4,9,1]],\n",
    "                 [[8,0,2],[2,4,5],[5,2,6],[7,5,3]],[[5,2,1],[5,4,2],[9,9,1],[3,4,2]]])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 4, 2]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[1,2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "img=numpy.array([[[4,5,4,2],[1,3,1,2],[7,4,2,3],[4,9,1,3]],\n",
    "                 [[8,0,2,4],[2,4,5,3],[5,2,6,1],[7,5,3,2]],[[5,2,1,2],[5,4,2,2],[9,9,1,1],[3,4,2,2]]])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 4, 5, 4, 2, 0, 0],\n",
       "        [0, 0, 1, 3, 1, 2, 0, 0],\n",
       "        [0, 0, 7, 4, 2, 3, 0, 0],\n",
       "        [0, 0, 4, 9, 1, 3, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 8, 0, 2, 4, 0, 0],\n",
       "        [0, 0, 2, 4, 5, 3, 0, 0],\n",
       "        [0, 0, 5, 2, 6, 1, 0, 0],\n",
       "        [0, 0, 7, 5, 3, 2, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 5, 2, 1, 2, 0, 0],\n",
       "        [0, 0, 5, 4, 2, 2, 0, 0],\n",
       "        [0, 0, 9, 9, 1, 1, 0, 0],\n",
       "        [0, 0, 3, 4, 2, 2, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C, H, W=img.shape\n",
    "new_image=[]\n",
    "m, n = (2, 2)\n",
    "#new_image = numpy.zeros(shape = (C, H+2*m, W+2*n))\n",
    "for j in range(C):\n",
    "    new_layer=[]\n",
    "    for i in range(H + 2 * m):\n",
    "        if i <= m-1 or i >= H + m:\n",
    "            new_layer.append([0] * (W + 2 * n))\n",
    "        else:\n",
    "            new_layer.append([0] * n + img[j,i - m].tolist() + [0] * n)\n",
    "    new_image.append(new_layer)\n",
    "img = numpy.array(new_image)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 9., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = numpy.zeros(shape=(2, 3, 4))\n",
    "a[1,1,1]=9\n",
    "a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1]\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd7186c031ec73d1ebdbc77ad43b3a40",
     "grade": true,
     "grade_id": "cell-f7bf854bb0ec733e",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def Conv2D(img, kernel, bias, stride, padding):\n",
    "    \"\"\"2D convolutional operation.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        img : np.array\n",
    "            A 3D array of shape (C,H,W).\n",
    "        kernel : np.array, just a filter\n",
    "            the weights of the kerel. \n",
    "            A 4D array of shape (out_channels, in_channels, kernel_height, kernel_width).\n",
    "        bias : np.array\n",
    "            the biases of the layer. \n",
    "            A 1D array of shape (out_channels).\n",
    "        strides : tuple\n",
    "            the strides of the convolution operation. \n",
    "            A tuple of shape (height_stride, width_stride).\n",
    "        padding : tuple\n",
    "            the number of zero paddings along the height and width. \n",
    "            A tuple of shape (height_padding, width_padding).\n",
    "\n",
    "        kernel_size = kernel.shape\n",
    "        stride = (stride, stride) if type(stride) == int else stride\n",
    "        padding = (padding, padding) if type(padding) == int else padding\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        The output of the layer. \n",
    "        A 3D array of shape (out_channels, out_heights, out_weights).\n",
    "    \"\"\"\n",
    "    # 1. padding\n",
    "    new_image = []\n",
    "    m, n = padding\n",
    "    C, H, W = img.shape\n",
    "    for j in range(C):\n",
    "        new_layer=[]\n",
    "        for i in range(H + 2 * m):\n",
    "            if i <= m-1 or i >= H + m:\n",
    "                new_layer.append([0] * (W + 2 * n))\n",
    "            else:\n",
    "                new_layer.append([0] * n + img[j,i - m].tolist() + [0] * n)\n",
    "        new_image.append(new_layer)\n",
    "    img = numpy.array(new_image)\n",
    "                \n",
    "    # 2. check dimensions\n",
    "    # check whether kernel's in_channel == img's depth channel\n",
    "    \n",
    "    out_channels, in_channels, kernel_height, kernel_width = kernel.shape\n",
    "    if in_channels != C:\n",
    "        print (\"Error: Number of channels in both image and filter must match.\")\n",
    "        sys.exit()\n",
    "        \n",
    "    # check whether the filter is a square matrix\n",
    "    if kernel_height != kernel_width:\n",
    "        print(\"Error: Filter is not a square matrix\")\n",
    "        sys.exit()\n",
    "        \n",
    "    # check whether the size of the filter is odd\n",
    "    if kernel_height % 2 == 0:\n",
    "        print(\"Error: Filter size must be an odd\")\n",
    "        sys.exit()\n",
    "        \n",
    "    # check the dimension of H_after and W_after\n",
    "    p, q = stride\n",
    "    if (H - kernel_height + 2 * m) % p != 0:\n",
    "        print(\"Error: the new height is not integer\")\n",
    "        \n",
    "    if (W - kernel_width + 2 * n) % q != 0:\n",
    "        print(\"Error: the new width is not integer\")\n",
    "        \n",
    "    # H_after = (H - kernel_height + 2 * m) / p\n",
    "    # W_after = (W - kernel_height + 2 * n) / q\n",
    "    \n",
    "    # 3. conv operation\n",
    "    out_heights = (H - kernel_height + 2 * m) / p\n",
    "    out_widths = (W - kernel_width + 2 * n) / q\n",
    "    out = numpy.zeros(shape = (int(out_channels), int(out_heights), int(out_widths)))\n",
    "    \n",
    "    for k in range(int(out_channels)):\n",
    "        for i in range(int(out_heights)):\n",
    "            for j in range(int(out_widths)):\n",
    "                out[k,i,j] = numpy.sum(img[:,p*i:p*i+kernel_height,q*j:q*j+kernel_width]*kernel[k]) + bias[k]\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 78., 138., 121.],\n",
       "        [191., 267., 193.],\n",
       "        [210., 287., 203.]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=numpy.array([[[4,5,4,2],[1,3,1,2],[7,4,2,3],[4,9,1,3]],\n",
    "                 [[8,0,2,4],[2,4,5,3],[5,2,6,1],[7,5,3,2]],[[5,2,1,2],[5,4,2,2],[9,9,1,1],[3,4,2,2]]])\n",
    "kernel=numpy.array([[[[1,2,3],[2,1,2],[3,5,2]],[[3,1,2],[2,1,5],[2,3,1]],[[4,1,4],[3,2,5],[3,2,1]]]])\n",
    "kernel.shape\n",
    "bias=[1]\n",
    "padding=(1,1)\n",
    "stride=(1,1)\n",
    "Conv2D(img, kernel, bias, stride, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/u/cs249/data/conv_cases.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-94c8ae94afda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'conv_cases.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconv_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mconv_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconv_cases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/u/cs249/data/conv_cases.pkl'"
     ]
    }
   ],
   "source": [
    "with open(data/'conv_cases.pkl', 'rb') as conv_f:\n",
    "    conv_cases = pickle.load(conv_f)\n",
    "    for case in conv_cases:\n",
    "        weight = case['weight']\n",
    "        bias = case['bias']\n",
    "        x = case['x']\n",
    "        out = case['out']\n",
    "        stride = case['stride']\n",
    "        pad = case['pad']\n",
    "        conved= Conv2D(x,weight,bias,stride,pad)\n",
    "        assert np.allclose(conved, conved),'not pass'\n",
    "    print(\"Implemented Correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Problem 2.3 CNN with CIFAR-10\n",
    "#### a.prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.CIFAR10(root=data, train=True,download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root=data, train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=True, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(images).numpy(), (1, 2, 0)))\n",
    "plt.title('         '.join('%5s' % classes[labels[j]] for j in range(4)),fontsize=40,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. define network\n",
    "- Two-layer CNN with maxpooling in between, following with 2 FC layers for classification\n",
    "- Use `LeakyReLU` as your activation function\n",
    "- You need to choose your own parameter for above layer to get a good result\n",
    "- Please visist https://pytorch.org/docs/stable/nn.html for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3547e920e67f0ffb4247215e63f766ec",
     "grade": true,
     "grade_id": "cell-6b582ddd2a0f2c93",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d -> view -> linear -> relu -> linear -> relu -> linear\n",
    "import torch\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 3 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(576, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = torch.nn.functional.max_pool2d(torch.nn.functional.leaky_relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = torch.nn.functional.max_pool2d(torch.nn.functional.leaky_relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = torch.nn.functional.leaky_relu(self.fc1(x))\n",
    "        x = torch.nn.functional.leaky_relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "tensor([[0.4979, 0.5297, 0.5158, 0.4801, 0.4785, 0.4715, 0.4848, 0.4908, 0.5145,\n",
      "         0.4668]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. define criterion and optimizer\n",
    "\n",
    "1. Define criterion for multi-label classification\n",
    "2. Define optimizer for training net.parameter()\n",
    "3. You need to choose your own parameter for optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f35a441bec431447d49b6615d9c034c",
     "grade": true,
     "grade_id": "cell-7ec599d185d5ab67",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-3)\n",
    "criterion = torch.nn.LogSoftmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. training\n",
    "The same as before, for training, \n",
    "1. calculate the loss wrt the ground-truth \n",
    "2. backdrop the loss to optimize the network.\n",
    "3. compute accuracy at the end of **each epoch**\n",
    "\n",
    "Plot the loss for each epoch which is defined as the average of all sample's loss within one epoch  \n",
    "\n",
    "Hint:use below snippet to put data on GPU\n",
    "\n",
    ">```python\n",
    ">inputs = inputs.cuda()\n",
    ">labels = labels.cuda()\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d948aabf031d2ea317106a34f9a4240",
     "grade": true,
     "grade_id": "cell-a324bf9cee55ad4c",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c807d8fc29e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    optimizer.zero_grad() \n",
    "    # Forward pass\n",
    "    y_pred = net(images)\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, labels)\n",
    "    # Print loss in each iteration\n",
    "    print('Epoch {}: train loss: {}'.format(i, loss.item()))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
