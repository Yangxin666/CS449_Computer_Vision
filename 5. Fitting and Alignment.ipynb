{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.rochester.edu/assets/images/ur-logo.svg\">\n",
    "\n",
    "# <center>[CSC 249/449: Machine Vision](https://www.cs.rochester.edu/~cxu22/t/249F20/)</center>\n",
    "\n",
    "## Homework Submission\n",
    "After completed the homework notebook. \n",
    "- Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`, as well as your NetID below.\n",
    "- `Kernel`$\\rightarrow$ `Restart & Run All` (in the menubar).\n",
    "- You can generated zip file using following command:\n",
    "    ```python\n",
    "    NetID=''\n",
    "    make_submission(NetID)\n",
    "    ```\n",
    "- Double-check **generated zip file**, text, math, code, outputs, figures. Re-run if needed.\n",
    "- Sumbit the zip file via blackboard.\n",
    "- 1% deduction of late assignment total score per hour passing the deadline.\n",
    "---------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Fitting and Alignment\n",
    "Last time, you have already found the matches between two images.  \n",
    "We will use these matched points to find the **perspective transformation** between two images and finally stitch them together in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs249 import *\n",
    "img1 = cv2.cvtColor(cv2.imread(str(data/'left.png')), cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(cv2.imread(str(data/'right.png')), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we first show the matches from `harris corner` + `SIFT descriptor.`\n",
    "Many hyperparameters make this harris corner hard to fine-tune, so the result is not always good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1=cv2.goodFeaturesToTrack(cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY), 1000, 0.1, 3)\n",
    "kp2=cv2.goodFeaturesToTrack(cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY), 1000, 0.1, 3)\n",
    "kp1= [cv2.KeyPoint(float(x[0][0]), float(x[0][1]), 1) for x in kp1]\n",
    "kp2= [cv2.KeyPoint(float(x[0][0]), float(x[0][1]), 1) for x in kp2]\n",
    "sift = cv2.SIFT_create()\n",
    "k1, d1 = sift.compute(img1,kp1)\n",
    "k2, d2 = sift.compute(img2,kp2)\n",
    "img,_=findMatch(img1,k1,d1,img2,k2,d2)   \n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the drawback of the harris corner, the state of the art approach: SIFT comes in.  \n",
    "You don't have to spend much time to find the good parameter, it'll find the keypoints and descriptor at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1, d1 = sift.detectAndCompute(cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY),None)\n",
    "k2, d2 = sift.detectAndCompute(cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY),None)\n",
    "img,matches=findMatch(img1,k1,d1,img2,k2,d2)   \n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1  Image stitching\n",
    "As you can see, although we can find good matches between two images, there are still many outliers(mismatch).    \n",
    "Because of these outliers, we cannot use simple regression to find the transformation between two images.  \n",
    "Therefore we need to implement RANSAC which is a general framework for model fitting in the presence of outliers.\n",
    "\n",
    "We use homogeneous coordinates here, which means representing a 2D vector (x, y) as a 3D vector (x, y, 1).\n",
    "\n",
    "Fitting with perspective matrix means given a set of matched feature points $\\{p1,p2\\}$ we want to find a `3*3` Projective Transform (Homography) matrix $\\mathcal{H}$ so that\n",
    "$$\n",
    "w*p_2 =  \\mathcal{H} * p_1, \n",
    "$$\n",
    "where $w$ is a unknown scale factor.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Given four matches Compute $\\mathcal{H}$ with Direct Linear Transform\n",
    ">Hint: you might need to use `np.linalg.svd()` to compute the SVG decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c988479bf5e3ced119745fa5d270b1fc",
     "grade": true,
     "grade_id": "cell-dbecd9faa66e9d15",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def computeHomographyMatrix(fourcorrs):\n",
    "    # Compute H using DLT with four point correspondences\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Count inliers with geometric distance\n",
    "After you finding the transform matrix, you need to find the fraction of inliers within a preset threshold of the model.  \n",
    "Specifically, we iterate through all matched points and if\n",
    "$$\n",
    "p_2 - p_1*\\mathcal{H}<threshold\n",
    "$$\n",
    "we'll consider this match as a inlier.\n",
    "\n",
    "You need to return all inliers with below function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "035f4a433bd46e9bf96b7313db9e31fc",
     "grade": true,
     "grade_id": "cell-7c77364f0857aba3",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def getInliers(corrList, h, threshold=5):\n",
    "    inliers = []\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. RANSAC\n",
    "\n",
    "RANSAC outline:  \n",
    "\n",
    "1. Randomly select four matches. \n",
    ">Hint: you can use `random.sample()` to randome select from a list.\n",
    "2. Solve for $\\mathcal{H}$ parameters using sampled matches. Use `computeHomographyMatrix()` defined above.\n",
    "3. Find all inliners with last step $\\mathcal{H}$. Use `getInliers()` defined above.\n",
    "\n",
    "Repeat 1-3 until # of inliners is greater than (# of all matches) * threshold, then return $\\mathcal{H}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54ba58f007ac5b53136851f97bd011ee",
     "grade": true,
     "grade_id": "cell-d1a168f910511dfa",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ransac(corrList, thresh):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.Perspectative tranformation\n",
    "\n",
    "After getting the transformation between two images, the last step is to stitch them together.  \n",
    ">Hint:You can use `cv2.perspectiveTransform` in your implementation to transform the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ca9e3a9a057d87478e06e6c6fee88ca",
     "grade": true,
     "grade_id": "cell-bc243d879fd1ac23",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def stitch(img1,img2,H):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrList = []\n",
    "for match in matches:\n",
    "    (x1, y1) = k1[match.queryIdx].pt\n",
    "    (x2, y2) = k2[match.trainIdx].pt\n",
    "    corrList.append([(x1, y1), (x2, y2)])\n",
    "H= ransac(corrList, 0.6)\n",
    "result = stitch(img1,img2,H)\n",
    "plt.figure(figsize=(15,20))\n",
    "plt.axis('off')\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2 Hough Transform (CSC 449 ONLY and extra bonus for CSC 249)\n",
    "Find the coordinates and radius of these circles.\n",
    "\n",
    "Use the Hough Transform with right $R$ first to transform the image to parameter space, and then find the local maximum as coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(cv2.imread(str(data/'circles.png')), cv2.COLOR_BGR2GRAY)\n",
    "img[img<img.max()*0.5]=0\n",
    "img[img>0]=255\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Hough transform\n",
    "No build-in functions are al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cd926b92c8d33b22f760291271022a7",
     "grade": true,
     "grade_id": "cell-ce2dfe09767d87f1",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def houghtrans(img,R):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.Detect local maxmium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9421d233e70083fd7c2697d7e54aeac",
     "grade": true,
     "grade_id": "cell-45e709077f66eeb3",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
