{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.rochester.edu/assets/images/ur-logo.svg\">\n",
    "\n",
    "# <center>[CSC 249/449: Machine Vision](https://www.cs.rochester.edu/~cxu22/t/249F20/)</center>\n",
    "\n",
    "## Homework Submission\n",
    "After completed the homework notebook. \n",
    "- Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`, as well as your NetID below.\n",
    "- `Kernel`$\\rightarrow$ `Restart & Run All` (in the menubar).\n",
    "- You can generated zip file using following command:\n",
    "    ```python\n",
    "    NetID=''\n",
    "    make_submission(NetID)\n",
    "    ```\n",
    "- Double-check **generated zip file**, text, math, code, outputs, figures. Re-run if needed.\n",
    "- Sumbit the zip file via blackboard.\n",
    "- 1% deduction of late assignment total score per hour passing the deadline.\n",
    "---------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. RNN\n",
    "----\n",
    "### Problem 2.1 Sequence modeling with LSTM\n",
    "\n",
    "In this Problem, we will try to do time series forecasting with our LSTM cell for on coronavirus cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x132cc07f0>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEDCAYAAAAcI05xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAe+UlEQVR4nO3dd3xUZd7+8c+X0EOHSAsh9CKYBCJF115RV9RV1nUVRNeI7lr2saw+rru2fdxd2+paEVERlSZY14ooiwVJIPTeE1ooCSU9uX9/ZPQXNYEBZuacTK736+WLYeYwuW5OuDw5c59zm3MOERHxrzpeBxARkYNTUYuI+JyKWkTE51TUIiI+p6IWEfE5FbWIiM+FrajNbLyZ7TCzJUFuP8LMlpnZUjN7I1y5RERqGgvXPGozOxnYD0xwzvU7xLY9gCnA6c65PWZ2jHNuR1iCiYjUMGE7onbOzQZ2V37OzLqZ2UdmlmFm/zWz3oGXrgOecc7tCfxZlbSISECkz1GPBW5yzg0EbgeeDTzfE+hpZl+Z2bdmdm6Ec4mI+FbdSH0hM2sCnABMNbPvn25QKUcP4FQgHphtZv2dc7mRyici4lcRK2oqjt5znXPJVbyWBcx1zpUA681sFRXFPS+C+UREfClipz6cc3upKOHLAKxCUuDlt6k4msbM2lBxKmRdpLKJiPhZOKfnvQl8A/Qysywzuxb4LXCtmS0ElgLDA5t/DOwys2XALOAO59yucGUTEalJwjY9T0REQkNXJoqI+FxYPkxs06aNS0xMDMdbi4hEpYyMjJ3OubiqXgtLUScmJpKenh6OtxYRiUpmtrG613TqQ0TE51TUIiI+p6IWEfE5FbWIiM+pqEVEfE5FLSLicypqERGfU1GLiIRAxsY9jJ29NizvraIWETlKc9ftYuRLc3lj7ib2F5WG/P1V1CIiR+GrNTu5+uV5tGvekMnXD6VJg9Bf8K2iFhE5Qu9kZjP6lXkktGrMpLShtG3WMCxfJ5IrvIiIRIXycse/PlvFU5+vYVCXVrxw5UBaxtYP29dTUYuIHIbCkjJum7qQDxZtZURqPA9d1J/6dcN7cuKQRW1mvYDJlZ7qCvzFOfevcIUSEfGjwpIyRr88j2/X7+LuYb1JO7krlRbrDptDFrVzbiWQDGBmMUA2MCO8sURE/KW0rJyb3lzAN+t28cSvk7g4JT5iX/twj9fPANY656q9b6qISLQpL3f86a3FfLpsO/dfeGxESxoOv6gvB96s6gUzSzOzdDNLz8nJOfpkIiI+UFbuuHv6Yt6an8Ufz+zJqBMSI54h6KI2s/rAhcDUql53zo11zqU651Lj4qpcTUZEpEYpKC7jxtczmJy+mZvP6MHNZ3T3JMfhzPoYBsx3zm0PVxgREb8oKC7jmlcqPjj8ywV9ueYXXTzLcjhF/RuqOe0hIhJN8otLufaVdOau38UTI5K5KKWjp3mCOvVhZrHAWcD08MYREfFW5ZJ+3AclDUEeUTvnDgCtw5xFRMRT+cWlXPPKPL5bv5snfp3M8GTvSxp0rw8REcC/JQ0qahERX5c06F4fIlLL5ReXMvrleczb4M+SBhW1iNRiu/YXcd2EdDI35/q2pEFFLSK11Mpt+7huQjrb9xby7G8HcG6/9l5HqpaKWkRqnY+WbON/pmTSpEFdJqUNISWhpdeRDkpFLSK1Rnm548mZq3ly5mqSOrVg7FUDw7YqSyipqEWkVigpK+f2qQt5J3MLvxoQz98u7kfDejFexwqKilpEol5pWTm/f30+nyzbzh3n9OLGU7tF5Ib/oaKiFpGoVlhSxp3TFvHJsu3c98u+XH2idzdXOlIqahGJWtm5BdwwMYNFWXnceW6vGlnSoKIWkShUXu54OzObhz5YTnFpOS9cNZBzjm3ndawjpqIWkaiycHMuf3l3KQs355IU35zHf51Mt7gmXsc6KipqEYkaz32xlkc/WUnr2Po8dlkSF6d0pE6dmvOhYXVU1CISFZ6ZtYZHPl7J+ce15/8u7k/zRvW8jhQyKmoRqfFe+2YDj3y8kuHJHXhiRHJUHEVXptucikiN9uZ3m7j3naWc2actj16WFHUlDTqiFpEa7KU563nw/WWc1iuOp69IoV5MdB57BrtmYgszm2ZmK8xsuZkNDXcwEZGDefrz1Tz4/jKG9WvHC1el1pjLwY9EsEfUTwIfOecuNbP6QOMwZhIRqVZ5ueMfH6/ghS/XcXFKRx659DjqRumR9PcOWdRm1hw4GbgawDlXDBSHN5aIyM/l5Zdw6+QFzFqZwxWDE3hoeL+oPCf9U8EcUXcBcoCXzSwJyABuCaxM/gMzSwPSABISEkKdU0RquQ07DzDq5e/YklvAgxf148rBCTXqxkpHI5ifF+oCA4DnnHMpwAHgrp9u5Jwb65xLdc6lxsXFhTimiNRmm3fnc8WL37KvsJRJaUO4akjnWlPSEFxRZwFZzrm5gd9Po6K4RUTCbmteAVeM+5YDxWVMvHYwAzu38jpSxB2yqJ1z24DNZtYr8NQZwLKwphIRAXbsLeSKF+eSe6CECdcMom+HZl5H8kSwsz5uAl4PzPhYB4wOXyQRkYoVwn87bi7b9xYy4ZpBJHVq4XUkzwRV1M65TCA1vFFERCrs2FfIqPHz2LQ7n1dGDyI1sfad7qhMVyaKiK+s2r6P0S/PY/eBYsaOTGVot9ZeR/KcilpEfOPrtTu5fkIGDevHMOX6ofSPb+51JF9QUYuIL8xauYPrX8sgsXVjXh49iI4tGnkdyTdU1CLiuY+XbuMPb8ynZ9umvHbtYFrF1vc6kq+oqEXEU+8t3MKtkzPp37E5r14zKKpu+B8qKmoR8cy0jCzunLaQ1M6tGD/6eJo0UCVVRX8rIuKJN+Zu4p63F3NitzaMHTmQxvVVR9XR34yIRFzlG/4/d+XAqL6XdCioqEUkor5fhHZYv3Y8eXkK9etG972kQ0FFLSIR4ZzjsU9W8fSsNbXmhv+hoqIWkbBzzvG3D5Yzbs56fjOoE3+7qH+tuOF/qKioRSTs/vnxSsbNWc/VJyTy11/2rVX3kg4F/dwhImE18duNPPfFWn47OEElfYRU1CISNouycnngvWWc2iuOB4b3U0kfIRW1iIRFbn4xN0ycT1zTBjwxIpkYnZM+YjpHLSIhV17uuG3KQnbsK2TqmBNoqXt3HBUdUYtIyD335VpmrtjBvRf0JbkWr8wSKipqEQmpdzKzefSTlfwyqQNXDensdZyoENSpDzPbAOwDyoBS55yW5RKRn5m1Yge3TVnIoMRWPHLpcfrwMEQO5xz1ac65nWFLIiI12nfrdzNmYga92zdl3KhU3b8jhHTqQ0SO2tIteVz7yjw6tmzEq6MH0bSh7ikdSsEWtQM+MbMMM0uragMzSzOzdDNLz8nJCV1CEfG1PQeKSZuQQZOGdZl47WBaN2ngdaSoE2xR/8I5NwAYBvzezE7+6QbOubHOuVTnXGpcXFxIQ4qIP5WVO26ZnEnOviKev3IgHbTOYVgEVdTOuezArzuAGcCgcIYSkZrhyZmrmb0qh79e2JckTcMLm0MWtZnFmlnT7x8DZwNLwh1MRPzt8xXbeWrmai4dGM8VgxK8jhPVgpn10RaYEZhmUxd4wzn3UVhTiYivbdqVz62TMunbvhkPXaR7eITbIYvaObcOSIpAFhGpAQpLyhgzMQOA57WMVkToXh8iEjTnHPe+vYRlW/fy0qhUElo39jpSraB51CIStInfbmRqRhY3nd6dM/q09TpOraGiFpGgTJ+fxV/eXcoZvY/h1jN7eh2nVlFRi8gh/WfxVm6fupChXVvzzG8H6N7SEaaiFpGDWrg5l1snZTIgoSUvjtQ9PLygohaRauUVlHDj6xWrtLw4MpXYBpp/4AX9rYtItf72wTK27S1k2pihWqXFQzqiFpEqzV6Vw5T0LNJO7kpKQkuv49RqKmoR+Zn9RaXcPX0xXeNiueWMHl7HqfV06kNEfuYfH65gS14B08YM1YeHPqAjahH5ke/W7+a1bzdy9QmJDOzcyus4gopaRCopLCnjrrcWEd+yEbef3cvrOBKgUx8i8oN/f76adTsPMOGaQZqK5yM6ohYRAL5eu5Pnv1zHpQPjObmnVmnyExW1iJCdW8Af3lhAlzax3HfhsV7HkZ9QUYvUcoUlZYx5LYOS0nJeuGogTXTKw3e0R0Rqucc+Wcni7DxeHJlKt7gmXseRKuiIWqQWW5Kdx0tz1nPF4ATO6qv7S/tV0EVtZjFmtsDM3g9nIBGJjNKycu6avojWTRrwp3N7ex1HDuJwjqhvAZaHK4iIRNYrX29gSfZe7r/wWJo3qud1HDmIoIrazOKB84Fx4Y0jIpGweXc+j32yijP7HMOwfu28jiOHEOwR9b+AO4Hy6jYwszQzSzez9JycnFBkE5EwcM7x57eXUMfggeH9MNNqLX53yKI2swuAHc65jINt55wb65xLdc6lxsVpsryIX723aCtfrsrh9nN60aFFI6/jSBCCOaI+EbjQzDYAk4DTzWxiWFOJSFjsOVDMA+8tJSm+OSOHJnodR4J0yKJ2zt3tnIt3ziUClwOfO+euDHsyEQkp5xx3T19MXkEJD19ynBaorUE0j1qklpiansVHS7dx+9m96Nuhmddx5DAc1pWJzrkvgC/CkkREwmbDzgPc995ShnZtzXUndfU6jhwmHVGLRLmSsnJunZxJ3TrGYyOSqKNTHjWO7vUhEuX+PXM1mZtzefqKFM3yqKF0RC0SxdI37ObpWWu4ZEBHLjiug9dx5AipqEWiVEFxGX+ckknHlo24X/eYrtF06kMkSj37xRo27y5gUtoQmjbUvTxqMh1Ri0ShDTsP8MKX67gouQNDurb2Oo4cJRW1SBR68P1l1Isx7j6vj9dRJARU1CJRZuby7cxcsYNbzuxB22YNvY4jIaCiFokiewtL+PPbS+jZtglXn9DF6zgSIipqkSjy0PvL2L63kH9emkT9uvrnHS20J0WixAeLtjIlPYvrT+lGcqcWXseREFJRi0SB7NwC7p6+iKROLfifs3p6HUdCTEUtUsOVlpVz66QFlDt46vJk6sXon3W00QUvIjXc07PWMG/DHp74dRKdW8d6HUfCQP/rFanB0jfs5qmZq7k4pSMXp8R7HUfCREUtUkPlFZRwy6RM4ls25oHhupdHNNOpD5Ea6v73lrJtbyHTxgzVvTyinI6oRWqgWSt3MH1+Njec0o2UhJZex5EwO2RRm1lDM/vOzBaa2VIzuz8SwUSkajv3F3HntEX0OKYJN53R3es4EgHBnPooAk53zu03s3rAHDP70Dn3bZizichPlJc7bp+6kLyCEl4dPYgGdWO8jiQRcMgjaldhf+C39QL/ubCmEpEqvfz1Br5YmcM95/XRSuK1SFDnqM0sxswygR3Ap865uVVsk2Zm6WaWnpOTE+KYIrIkO4+/f7icM/u0ZeTQzl7HkQgKqqidc2XOuWQgHhhkZv2q2Gascy7VOZcaFxcX4pgitdv+olJufnMBrWMb8Milx2GmlcRrk8Oa9eGcywVmAeeGJY2I/ExhSRm/e3UeG3fn88Svk2kZW9/rSBJhwcz6iDOzFoHHjYCzgBVhziUiQHFpOTdMzGDu+t08PiKJod20rFZtFMysj/bAq2YWQ0WxT3HOvR/eWCJSVu744+RMZq3M4eFL+jM8uaPXkcQjhyxq59wiICUCWUQkwDnH/05fzAeLt/Ln8/vwm0EJXkcSD+nKRBEfevG/65icvpk/nNad353U1es44jEVtYjPzFqxg4c/XMF5/dtpEQABVNQivrJy2z5ufnMBfdo149HLkqhTR9PwREUt4htZe/IZOX4ujerH8OKoVBrX180tpYK+E0R8YPeBYkaO/4784jKmXD+Uji0aeR1JfERFLeKxHXsLGfXyPLL2FPDaNYPo01738JAfU1GLeGj9zgOMHD+XXfuLGTcylcFddUGL/JyKWsQjy7fu5cpxc3HAm9cNIalTC68jiU+pqEU8sHRLHleOm0uDujG8ft1gusU18TqS+JiKWiTCFmXlMnL8dzSqF8Ob1w0hsU2s15HE5zQ9TySCPli0lREvfENs/bpMThuqkpag6IhaJAKcczw1cw1PfLaKgZ1b8sJVA2nTpIHXsaSGUFGLhFleQQn3zFjM+4u2csmAjjx8SX+tdSiHRUUtEkYfLdnKve8sZdf+Iu4a1pvrT+6q1VnksKmoRcJgb2EJ98xYwnsLt3Bsh2aMH3U8/eObex1LaigVtUiIzVm9kzunLWT7viJuP7snY07pRt0YfW4vR05FLRIiu/YX8dinq3hj7ia6xsUybcxQUhJaeh1LooCKWuQo7S0sYdzsdbw0Zz0FJWVcd1IXbju7Fw3r6QNDCY1DFrWZdQImAG0BB4x1zj0Z7mAifldQXMar32zguS/WkldQwvnHteePZ/ak+zG6ylBCK5gj6lLgNufcfDNrCmSY2afOuWVhzibiS8Wl5Uyet4mnPl9Dzr4iTu0Vx+1n96JfR31YKOERzOK2W4Gtgcf7zGw50BFQUUutUlbueHtBNk98toqsPQUcn9iSZ64YwKAurbyOJlHusM5Rm1kiFSuSzw1LGhEf2nOgmMnpm3ntm41k5xZwbIdmPHRRP07pGac50RIRQRe1mTUB3gJudc7treL1NCANICFBS9tLzbc4K49Xv9nAuwu3UFxazpCurbj3gr6c3bet1jKUiAqqqM2sHhUl/bpzbnpV2zjnxgJjAVJTU13IEopE2JLsPP758Upmr8qhcf0YRqTGc9WQRHq1a+p1NKmlgpn1YcBLwHLn3OPhjyTijYyNe3hx9jo+WrqNFo3rcdew3lwxOIFmDet5HU1quWCOqE8ErgIWm1lm4Ln/dc79J2ypRCKkrNzx6bJtjJ29jvmbcmnWsC43nd6d607uqoIW3whm1sccQCfkJKrkF5cyNT2L8V+tZ+OufDq1asR9v+zLZamdiG2g68DEX/QdKbVKSVk5k+Zt5snPVrFzfzEpCS3407m9OefYdsToA0LxKRW11ApFpWW8vSCb579cx/qdBxjUpRXPX9mL1ETNgRb/U1FLVMsrKOH1uRt5+asN5Owrom/7Zrw0KpXTex+jOdBSY6ioJSpt3p3P+K/WM2XeZg4Ul3FSjzY8MSKZE7u3VkFLjaOilqiycts+npq5mg+XbKWOGb9M6sDvTurCsR10Hw6puVTUEhV27C3k8U9XMSV9M7EN6pJ2cjdGndCZ9s0beR1N5KipqKVGy9lXxPNfrmXitxspd47RJ3bhptO706Jxfa+jiYSMilpqpA07D/DSnPVMzdhMcWk5F6fEc/MZ3encOtbraCIhp6KWGmXz7nwe/WQl7y7cQr06dbgopQM3nNqdLm1U0BK9VNRSI+Tll/Dsl2t4+asN1DEYc0o3Rp+YyDFNG3odTSTsVNTia4UlZbzy9QaenbWGfUWlXJzSkTvO6aUPCaVWUVGLL+0vKuWtjCye+2It2/YWclqvOO48tzd92jfzOppIxKmoxVfy8kt4etZqJn23mX1FpQzs3JInL09mcNfWXkcT8YyKWnyhvNwxbX4Wf/9wBbn5xVxwXAdGn5hISkJLr6OJeE5FLZ5bnJXHX95dwoJNuaR2bsn9wwfpSkKRSlTU4pnvp9q9k7mFNk3q8+hlSVyS0lHrEYr8hIpaIm5/USlPzVzNK19twAx+f1o3xpzSjaZaUUWkSipqiajZq3K4e/pituQV8KsB8dx2dk9NtRM5BBW1REReQQl/+2AZU9Kz6BYXy7QxJzCwsz4oFAlGMKuQjwcuAHY45/qFP5JEm0+XbeeeGYvZdaCYG0/txs1n9KBhvRivY4nUGMEcUb8CPA1MCG8UiTYbdx3gwfeX8dnyHfRu15SXRh1P/3jN5hA5XMGsQj7bzBIjkEWixP6iUp6dtYZxc9ZTr45x97DejD6xC/Xr1vE6mkiNFLJz1GaWBqQBJCQkhOptpQZxzjF9fjYPf7iCnfuLuCi5A3cN60O75rpxksjRCFlRO+fGAmMBUlNTXajeV2qGfYUl3D19Me8v2sqAhBaMG5VKcqcWXscSiQqa9SFHLXNzLrdMWkDWngLuOKcXN5zSTRetiISQilqOWGlZOc9+sZYnZ66mXbOGTE4bQmpiK69jiUSdYKbnvQmcCrQxsyzgr865l8IdTPxtUVYu9769hIVZeQxP7sADw/vRvJGuLBQJh2BmffwmEkGkZsjNL+aRj1fyxnebaB3bgKd+k8KFSR28jiUS1XTqQ4L2waKt3PvOEnLzi7n6hET+eFZPmun+HCJhp6KWQ8orKOG+d5cyY0E2SfHNmXjtYPp20EorIpGiopaD+nrNTm6fupDt+4q49cwe/P607tSL0YUrIpGkopYq7TlQzP/9ZzlTM7Lo2iaW6TecQJLmRYt4QkUtP+KcY8aCbB76YDl7C0q44dRu3Hx6DxrV102URLyiopYfbNx1gHtmLGHOmp2kJLTg4Uv607udzkWLeE1FLTjnmJK+mfvfW0aMGQ8OP5YrBncmRlcXiviCirqWy8sv4a7pi/hwyTaGdG3F4yOS6dBCK66I+ImKuhbL2Libm9/MZPveQu4a1pu0k7rqHh0iPqSiroXKyx3Pz17LY5+sokOLhrylGR0ivqairmW25hVwx9RFzFmzk/OPa8/Dl/TX1YUiPqeirkXeW7iFe2YspqTM8fAl/bn8+E6Y6VSHiN+pqGuBvPwS/vLuEt7J3EJKQgueGJFMYptYr2OJSJBU1FFu9qoc/vTWInL2FXHbWT254dRu1NUl4CI1ioo6Su3aX8RDHyxnxoJsusbFMv3GEzguvoXXsUTkCKioo0xhSRmvfbORp2etIb+4lJtP786Np3WnYT1dAi5SU6moo8S+whLeysjixf+uJzu3gFN6xnHP+X3o2bap19FE5CipqGu4NTv2M+GbDbyVkcWB4jJSElrwj18dxy96tPE6moiESFBFbWbnAk8CMcA459zfw5pKqlVW7li+dS/frN3FrJU7+HrtLurH1OGCpPaMGpqoC1dEolAwi9vGAM8AZwFZwDwze9c5tyzc4Wqr0rJy8kvK2HOgmKw9BWzenc+m3fkszs5jwaZc9heVAtA1LpY7zunF5cd3onWTBh6nFpFwCeaIehCwxjm3DsDMJgHDgZAX9QX//i+FJeU45354zlXewFX58Iftf/xc5W1d1c//6M1//F7BvJ+rNk/Vob9/vqrsAOUOCkrKKC4t/1mumDpGz7ZNuSilA6mdWzG0W2vaNmv48wGISNQJpqg7Apsr/T4LGPzTjcwsDUgDSEhIOKIw3eOaUFIWKK5KF8xVvnau8pV0P34++G1//N72oz9f3ftW3vZHX6+aNz7U+1X5XkDD+jE0rleX2AYxNGtUj04tGxPfshHtmzfU/GeRWipkHyY658YCYwFSU1OrOFY9tH9dnhKqOCIiUSOYQ7RsoFOl38cHnhMRkQgIpqjnAT3MrIuZ1QcuB94NbywREfneIU99OOdKzewPwMdUTM8b75xbGvZkIiICBHmO2jn3H+A/Yc4iIiJV0DQCERGfU1GLiPicilpExOdU1CIiPmeuquuoj/ZNzXKAjUf4x9sAO0MYx+803uim8Ua/UI25s3MurqoXwlLUR8PM0p1zqV7niBSNN7ppvNEvEmPWqQ8REZ9TUYuI+Jwfi3qs1wEiTOONbhpv9Av7mH13jlpERH7Mj0fUIiJSiYpaRMTnfFPUZnauma00szVmdpfXecLBzDaY2WIzyzSz9MBzrczsUzNbHfi1pdc5j4aZjTezHWa2pNJzVY7RKjwV2OeLzGyAd8mPTDXjvc/MsgP7OdPMzqv02t2B8a40s3O8SX3kzKyTmc0ys2VmttTMbgk8H5X7+CDjjew+ds55/h8Vt09dC3QF6gMLgb5e5wrDODcAbX7y3D+BuwKP7wL+4XXOoxzjycAAYMmhxgicB3xIxSpkQ4C5XucP0XjvA26vYtu+ge/tBkCXwPd8jNdjOMzxtgcGBB43BVYFxhWV+/gg443oPvbLEfUPC+g654qB7xfQrQ2GA68GHr8KXORdlKPnnJsN7P7J09WNcTgwwVX4FmhhZu0jEjREqhlvdYYDk5xzRc659cAaKr73awzn3Fbn3PzA433AcirWVY3KfXyQ8VYnLPvYL0Vd1QK6B/vLqKkc8ImZZQQWAwZo65zbGni8DWjrTbSwqm6M0bzf/xD4UX98pdNZUTVeM0sEUoC51IJ9/JPxQgT3sV+Kurb4hXNuADAM+L2ZnVz5RVfxs1NUz5esDWMEngO6AcnAVuAxT9OEgZk1Ad4CbnXO7a38WjTu4yrGG9F97JeirhUL6DrnsgO/7gBmUPEj0fbvfxQM/LrDu4RhU90Yo3K/O+e2O+fKnHPlwIv8/x99o2K8ZlaPitJ63Tk3PfB01O7jqsYb6X3sl6KO+gV0zSzWzJp+/xg4G1hCxThHBTYbBbzjTcKwqm6M7wIjAzMDhgB5lX58rrF+cg72Yir2M1SM93Iza2BmXYAewHeRznc0zMyAl4DlzrnHK70Ulfu4uvFGfB97/alqpU9Lz6PiE9W1wD1e5wnD+LpS8WnwQmDp92MEWgMzgdXAZ0Arr7Me5TjfpOJHwRIqzs9dW90YqZgJ8Exgny8GUr3OH6LxvhYYz6LAP9z2lba/JzDelcAwr/MfwXh/QcVpjUVAZuC/86J1Hx9kvBHdx7qEXETE5/xy6kNERKqhohYR8TkVtYiIz6moRUR8TkUtIuJzKmoREZ9TUYuI+Nz/AxuIC+oL9yNmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cs249 import *\n",
    "df = pd.read_csv('time_series_covid19_confirmed_US.csv')\n",
    "data=[int(v) for k,v in df.iloc[:, 11:].sum().to_dict().items()]\n",
    "plt.plot(range(len(data)),data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. perpare dataset\n",
    "\n",
    "In order to capture the local sequence pattern, we will slice data as sequences `[i,i+seq_length]` and the next data as predicted data. In other word, we are using a short period to predict one step further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdd7af5f6db70ce89fe5a5c0e1c8c2d2",
     "grade": true,
     "grade_id": "cell-2af832602c2dc90f",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# slice data with seq_length and y \n",
    "def get_sequences(data, seq_length):\n",
    "    list = []\n",
    "    pred = []\n",
    "    i = 0\n",
    "    while i < len(data)-seq_length:\n",
    "        list.append(data[i:i+seq_length])\n",
    "        if i+seq_length < len(data):\n",
    "            pred.append(data[i+seq_length])\n",
    "        i = i + 1\n",
    "    return np.asarray(list), np.asarray(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_length = 4\n",
    "x,y=[d.unsqueeze(-1).float() for d in list(map(torch.from_numpy, get_sequences(data, seq_length)))]\n",
    "x/=x.max()\n",
    "y/=y.max()\n",
    "assert(x.shape[0]+seq_length==len(data)), \"checkout dimension\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. implement LSTM cell\n",
    "In this part, you will implement your LSTM unit based on the following formulations:\n",
    "$$        \n",
    "\\begin{array}{ll} \\\\\n",
    "    i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
    "    f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\ \n",
    "    g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n",
    "    o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
    "    c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
    "    h_t = o_t \\odot \\tanh(c_t) \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d3580cc1fce22967f5e13cf039d9466",
     "grade": true,
     "grade_id": "cell-ae9b3eb4cd512450",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class LSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM cell implementation\n",
    "    Given an input x at time step t, and hidden and cell states: hidden = (h_(t-1), c_(t-1)),\n",
    "    you will implement a LSTM unit to compute and return (h_t, c_t)\n",
    "    hints: consider use linear layers to implement the several matrices W_* \n",
    "    Note: you just need to implement a one-layer LSTM unit\n",
    "    \"\"\"\n",
    "    # f_t: forget gate layer, i_t: input gate layer, g_t: input modulation gate layer, o_t & h_t: output gate, \n",
    "    # update cell state: c_t\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # forget gate components\n",
    "        self.linear_forget_w1 = nn.Linear(self.input_size, self.hidden_size, bias=True)\n",
    "        self.linear_forget_r1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.sigmoid_forget = nn.Sigmoid()\n",
    "\n",
    "        # input gate components\n",
    "        self.linear_gate_w2 = nn.Linear(self.input_size, self.hidden_size, bias=True)\n",
    "        self.linear_gate_r2 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.sigmoid_gate = nn.Sigmoid()\n",
    "\n",
    "        # cell memory components\n",
    "        self.linear_gate_w3 = nn.Linear(self.input_size, self.hidden_size, bias=True)\n",
    "        self.linear_gate_r3 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.activation_gate = nn.Tanh()\n",
    "\n",
    "        # out gate components\n",
    "        self.linear_gate_w4 = nn.Linear(self.input_size, self.hidden_size, bias=True)\n",
    "        self.linear_gate_r4 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.sigmoid_hidden_out = nn.Sigmoid()\n",
    "\n",
    "        self.activation_final = nn.Tanh()\n",
    "\n",
    "    def forget(self, x, h):\n",
    "        x = self.linear_forget_w1(x)\n",
    "        h = self.linear_forget_r1(h)\n",
    "        return self.sigmoid_forget(x + h)\n",
    "\n",
    "    def input_gate(self, x, h):\n",
    "\n",
    "        # Equation 1. input gate\n",
    "        x_temp = self.linear_gate_w2(x)\n",
    "        h_temp = self.linear_gate_r2(h)\n",
    "        i = self.sigmoid_gate(x_temp + h_temp)\n",
    "        return i\n",
    "\n",
    "    def cell_memory_gate(self, i, f, x, h, c_prev):\n",
    "        x = self.linear_gate_w3(x)\n",
    "        h = self.linear_gate_r3(h)\n",
    "\n",
    "        # new information part that will be injected in the new context\n",
    "        k = self.activation_gate(x + h)\n",
    "        g = k * i\n",
    "\n",
    "        # forget old context/cell info\n",
    "        c = f * c_prev\n",
    "        # learn new context/cell info\n",
    "        c_next = g + c\n",
    "        return c_next\n",
    "\n",
    "    def out_gate(self, x, h):\n",
    "        x = self.linear_gate_w4(x)\n",
    "        h = self.linear_gate_r4(h)\n",
    "        return self.sigmoid_hidden_out(x + h)\n",
    "\n",
    "    def forward(self, x, tuple_in):\n",
    "        (h, c_prev) = tuple_in\n",
    "        # input gate\n",
    "        i = self.input_gate(x, h)\n",
    "\n",
    "        # forget gate\n",
    "        f = self.forget(x, h)\n",
    "\n",
    "        # updating the cell memory\n",
    "        c_next = self.cell_memory_gate(i, f, x, h,c_prev)\n",
    "\n",
    "        # calculate the main output gate\n",
    "        o = self.out_gate(x, h)\n",
    "\n",
    "        # produce next hidden output\n",
    "        h_next = o * self.activation_final(c_next)\n",
    "\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "837d9d03ba58996da8f0170a512d68eb",
     "grade": true,
     "grade_id": "cell-d1381ef21883d4ff",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM cell implementation\n",
    "    LSTM is used to handle sequence and LSTMCell is responsible for computing one time step forward\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, seq_len):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # The input size\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # Dimension of weight vectors\n",
    "        self.hidden_dim = hidden_size\n",
    "        \n",
    "        # Number of time steps\n",
    "        self.sequence_len = seq_len\n",
    "        \n",
    "        # Initialize LSTM Cell\n",
    "        self.lstm_cell = LSTMCell(self.input_size, self.hidden_dim)\n",
    "        \n",
    "            \n",
    "    def forward(self, x, tuple_in):\n",
    "        # Creation of cell state and hidden state\n",
    "        (hidden_state, cell_state) = tuple_in\n",
    "\n",
    "        # Weights initialization\n",
    "        torch.nn.init.xavier_normal_(hidden_state)\n",
    "        torch.nn.init.xavier_normal_(cell_state)\n",
    "\n",
    "        hidden_state, cell_state = self.lstm_cell(x, (hidden_state, cell_state))\n",
    "    \n",
    "        return hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.  define network\n",
    "- We will define our `predictor` as one LSTM followed with one-layer MLP.\n",
    "- `predictor` will contain init hidden states for LSTM.\n",
    "- You will have to implement a `reset_hidden_state` function to reset the hidden states at the begining at each epoch.\n",
    "- Test your implementation by replacing the nn.LSTM from Pytorch with the nn.LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66dae50e55773384c73f005ab7afcf0b",
     "grade": true,
     "grade_id": "cell-1400d60e48543c20",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class COVIDPredictor(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden, seq_len):\n",
    "        super(COVIDPredictor, self).__init__()\n",
    "        #self.LSTM = nn.LSTM(n_features, 1, seq_len)\n",
    "        self.LSTM = LSTM(n_features, 1, seq_len)\n",
    "        self.lin1 = nn.Linear(1, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, 1)\n",
    "        self.num_layers = n_features\n",
    "        self.batch_size = seq_len\n",
    "        self.hidden_dim = n_hidden\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        h0 = torch.randn(250, 4, 1)\n",
    "        c0 = torch.randn(250, 4, 1)\n",
    "        return h0,c0\n",
    "    \n",
    "    def forward(self, x): \n",
    "        (h0, c0) = self.init_hidden()\n",
    "        out = self.LSTM(x,(h0, c0))\n",
    "        out = torch.nn.functional.leaky_relu(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.  Training\n",
    "\n",
    "We don't have test data to verify the performance, however you need to plot the traning loss to see whether it can converage or not. \n",
    "You are free to change the parameter for `n_hidder` ,optimiser parameter and epoch number to have a better loss curver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3919b69447fd88c5d015c869a5f012b4",
     "grade": true,
     "grade_id": "cell-43468dff37f3ebeb",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 32.12430191040039\n",
      "Epoch 1: train loss: 26.719192504882812\n",
      "Epoch 2: train loss: 27.890047073364258\n",
      "Epoch 3: train loss: 29.03240203857422\n",
      "Epoch 4: train loss: 27.949506759643555\n",
      "Epoch 5: train loss: 26.43635368347168\n",
      "Epoch 6: train loss: 25.638465881347656\n",
      "Epoch 7: train loss: 25.91195297241211\n",
      "Epoch 8: train loss: 26.347803115844727\n",
      "Epoch 9: train loss: 26.203737258911133\n",
      "Epoch 10: train loss: 25.52824592590332\n",
      "Epoch 11: train loss: 24.669422149658203\n",
      "Epoch 12: train loss: 24.306617736816406\n",
      "Epoch 13: train loss: 24.183090209960938\n",
      "Epoch 14: train loss: 24.438783645629883\n",
      "Epoch 15: train loss: 24.22360610961914\n",
      "Epoch 16: train loss: 23.809432983398438\n",
      "Epoch 17: train loss: 23.09742546081543\n",
      "Epoch 18: train loss: 22.899707794189453\n",
      "Epoch 19: train loss: 22.924985885620117\n",
      "Epoch 20: train loss: 22.578594207763672\n",
      "Epoch 21: train loss: 22.671125411987305\n",
      "Epoch 22: train loss: 21.959182739257812\n",
      "Epoch 23: train loss: 21.547178268432617\n",
      "Epoch 24: train loss: 21.22895050048828\n",
      "Epoch 25: train loss: 20.588150024414062\n",
      "Epoch 26: train loss: 20.848224639892578\n",
      "Epoch 27: train loss: 20.386627197265625\n",
      "Epoch 28: train loss: 20.0146484375\n",
      "Epoch 29: train loss: 19.591148376464844\n",
      "Epoch 30: train loss: 19.610258102416992\n",
      "Epoch 31: train loss: 19.689128875732422\n",
      "Epoch 32: train loss: 19.25952911376953\n",
      "Epoch 33: train loss: 18.20888900756836\n",
      "Epoch 34: train loss: 18.315044403076172\n",
      "Epoch 35: train loss: 17.997730255126953\n",
      "Epoch 36: train loss: 17.44386863708496\n",
      "Epoch 37: train loss: 17.06145477294922\n",
      "Epoch 38: train loss: 16.61015510559082\n",
      "Epoch 39: train loss: 16.210302352905273\n",
      "Epoch 40: train loss: 15.997783660888672\n",
      "Epoch 41: train loss: 16.030685424804688\n",
      "Epoch 42: train loss: 15.45711898803711\n",
      "Epoch 43: train loss: 15.244647979736328\n",
      "Epoch 44: train loss: 15.22605037689209\n",
      "Epoch 45: train loss: 14.898098945617676\n",
      "Epoch 46: train loss: 13.981021881103516\n",
      "Epoch 47: train loss: 14.34943962097168\n",
      "Epoch 48: train loss: 14.046036720275879\n",
      "Epoch 49: train loss: 14.185315132141113\n",
      "Epoch 50: train loss: 12.815412521362305\n",
      "Epoch 51: train loss: 12.73334789276123\n",
      "Epoch 52: train loss: 13.142659187316895\n",
      "Epoch 53: train loss: 11.451583862304688\n",
      "Epoch 54: train loss: 12.110158920288086\n",
      "Epoch 55: train loss: 11.537912368774414\n",
      "Epoch 56: train loss: 11.448226928710938\n",
      "Epoch 57: train loss: 11.482969284057617\n",
      "Epoch 58: train loss: 10.354752540588379\n",
      "Epoch 59: train loss: 10.313030242919922\n"
     ]
    }
   ],
   "source": [
    "model = COVIDPredictor(n_features=1,n_hidden=500,seq_len=seq_length)\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 60\n",
    "for t in range(num_epochs):  \n",
    "    model.zero_grad()\n",
    "    optimiser.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred[:,3,:], y)\n",
    "    print('Epoch {}: train loss: {}'.format(t, loss.item()))\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
